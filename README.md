# awesome-big-models [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

[![MIT License](https://img.shields.io/badge/license-MIT-green.svg)](https://opensource.org/licenses/MIT)

A collection of AWESOME things about big AI models.

## Models

- GPT-3 [[OpenAI]](https://openai.com/api/) [28 May 2020]

    Language Models are Few-Shot Learners [[NeurIPS'20]](https://papers.nips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf)  
    Field: NLP  
    #Params: 175 B  
    Training Data: ~680 B Tokens (45 TB)  
    Training Time: 95 A100 GPU years  
    Training Cost: $ 5M  
    Tags: Transformer

- 